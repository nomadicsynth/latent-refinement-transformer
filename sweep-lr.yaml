name: sweep-lr
project: science-llm
method: bayes
metric:
  name: eval/loss
  goal: minimize
parameters:
  muon-lr:
    min: 0.02
    max: 0.05
    distribution: log_uniform_values  
  # aux-adam-lr:
  #   min: 0.0009
  #   max: 0.01
  #   distribution: log_uniform_values
command:
  - ${env}
  - ${interpreter}
  - ${program}
  - --dataset-path
  - "./preprocessed_dataset_83208_9318"
  - --output-dir
  - "./results/sweep_lr"
  - --overwrite-output-dir
  - --no-backup
  - --use-wandb
  - --group
  - sweep-lr
  - --max-steps
  - "1000"
  - --eval-steps
  - "50"
  - --eval-samples
  - "500"
  - --save-strategy
  - "no"
  - --max-length
  - "32768"
  - --grad-checkpointing
  - --per-device-train-batch-size
  - "8"
  - --grad-accum
  - "2"
  - --hidden-size
  - "1024"
  - --intermediate-size
  - "4096"
  - --num-layers
  - "2"
  - --num-attention-heads
  - "8"
  - --num-kv-heads
  - "4"
  - --k-max
  - "32"
  - --tau
  - "0.999"
  - --lambda-ponder
  - "0.0025"
  - --halting-mass-scale
  - "0.0001"
  - --lambda-deep-supervision
  - "0.06"
  - --film-rank
  - "1024"
  - --use-liger-kernel
  - ${args}
program: train.py